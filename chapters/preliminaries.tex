\section{Preliminaries}
\label{sec:prelim}

		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:mis}{preliminaries/mississippi}{0.55}
			{Array representation of	`mississippi' string.}
			
Throughout this paper we represent the string we are searching as $S$ of length 
$|S| = N$, and the pattern we are searching for as $P$. $S[i]$ represents the 
symbol located at position $i$ in $S$, and $S[i..j]$ represents the substring of 
$S$ beginning at position $i$ and ending at $j$ inclusive. Strings are 
one-based, so in Figure \ref{fig:mis} $S[1] = $ `m', $S[3] = $ `s', and $S[1..3] 
= $ `mis'.

The $i^{th}$ \emph{suffix} is thus defined as $S[i..N]$, so the $1^{st}$ suffix 
in Figure \ref{fig:mis} is $S[1..12] = $ `mississipi\$', and the $5^{th}$ suffix 
is $S[5..12] = $ `issippi\$'. The $i^{th}$ prefix is defined as $S[1..i]$, so
the $5^{th}$ prefix in Figure \ref{fig:mis} is $S[1..5] = $ `missi'.

The $log$ operation is base 2 unless otherwise stated.

\subsection{Background}
In 1970 Knuth, Morris and Pratt (KMP) discovered an algorithm to match patterns 
in time proportional to the length of the text \cite{KMP77, 
McCreight76}. If the text is large, then KMP is ineffective for ranking and 
pattern discovery. KMP is only useful for exact matches. % TODO: other algs

One alternative to KMP for document ranking is the use of an inverted index, but
they must work with keywords and are thus inappropriate for many applications,
such as searches on certain oriental languages, and other strings that don't
have a clear definition of keywords (MIDI, for example). Suffix arrays are also 
more efficient than inverted files for searching phrases or partial 
patterns \cite{marin2003}. This was originally possible with a suffix 
tree~\cite{McCreight76}, although suffix trees require three to five times as 
much space~\cite{manber1993}.


\subsection{Suffix Arrays}
In its simplest form, a suffix array can be constructed for a string
$S[1..N]$ like so:

\begin{enumerate}
	\item
		Construct an array of pointers to all suffixes $S[1..N]$, 
		$S[2..N]$, ..., $S[N..N]$.
	\item
		Sort these pointers by the lexicographical ordering of their associated
		suffixes.
\end{enumerate}

Figure \ref{fig:mis} shows an example string, `mississippi'. The construction of 
the corresponding suffix array is shown in Figure \ref{fig:sa-make-mis}.

		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:sa-make-mis}{preliminaries/mississippi-sa-sort}{0.65}
			{Construction of Suffix Array for `mississippi'.}



\subsection{Burrows-Wheeler Transform}
The Burrows-Wheeler Transform (BWT) is calculated by $BWT[i] = S[SA[i]-1]$, and $BWT[1] = $ `\$', that is, the $i^{th}$ symbol of the BWT is the symbol prior to the $i^{th}$ suffix in the Suffix Array $SA$. See Figure \ref{fig:sa-bwt-mis}.

As proposed by Ferragina and Manzini, when a BWT is stored alongside a Suffix Array, it is known as a \emph{FM-Index} \cite{fmindex:ferragina2000}, which supports backwards search.

		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:sa-bwt-mis}{preliminaries/mississippi-sa}{0.35}
			{Suffix Array and Burrows-Wheeler Transform for
			`mississippi' string.}

\subsubsection{Rank Query}
A Rank Query on the string $S$ is defined as $rank_S(i, c) = n $, with $n$ being 
the number of times symbol $c$ appears in the range $S[1, i]$. This paper omits 
the subscript when the string we are querying is clear from the context. For 
example in Figure \ref{fig:rank-mis}, $rank(9, s) = 3$. If $i \le 0$ then 
$rank(i, c) = 0$.

		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:rank-mis}{preliminaries/rankquery}{0.6}
			{Rank query $rank(9, s) = 3$ on the Burrows-Wheeler Transform
			of `mississippi'.}

\subsubsection{Backward Search}
Since all occurrences of a search pattern $P$ lie in a contiguous portion of the 
Suffix Array, in earlier implementations we would locate the range that this 
pattern lies on by successive binary searches. Backward search utilises the BWT 
in a series of paired rank queries, further improving the query performance 
considerably ~\cite{claude2008, FGM09, ferragina07, GMR06, MN07:rankselect,
MN07:selfindex, marin2003, MN06}

Backward search issues $|P|$ pairs of rank queries will be issued, where $|P|$ 
denotes the length of the pattern. The paired rank queries are:

					$$ s' = C[P[i]] + rank(s - 1, P[i]) + 1$$
					$$ e' = C[P[i]] + rank(e, P[i])$$

Where $s$ denotes the start of the range, initially at $s = 1$, and $e$ is the 
end of the range, initially $e = N$.

In Figure \ref{fig:bws-1} there is a column $F$, which contains the first 
symbol for each suffix. Note that the $F$ column isn't stored as we store 
$C$ instead.

$C$ is an array\footnote{Note that we are indexing $C$ by a symbol $P[i]$, so 
this may be implemented with a suitable hash function.} containing the count of 
all symbols in $\Sigma$ which sort lexicographically before $P[i]$, where 
$\Sigma$ is the alphabet from our original string $S$, as in Figure 
\ref{fig:c-tab}.

In the first iteration 
we query the final character of the pattern, so $i = |P|$.  For each 
iteration, we decrement $i$ until $i = 1$. This maintains the invariant that
$SA[s..e]$ contains all the suffixes of which $P[i..|P|]$ is a prefix, and hence
all locations of $P[i..|P|]$ in $S$. This is illustrated in Figure 
\ref{fig:bws-2} through to Figure \ref{fig:bws-4}. If at any stage $e < 
s$, then the pattern doesn't exist in our original string.

An example is given in Figure \ref{fig:bws-1} through to Figure \ref{fig:bws-4},
Where the pattern \emph{`iss'} is searched for in the string `mississippi',
starting with $i = 3$, $P[3] = `s'$. The working for each rank query is shown 
below. We represent the current symbol as $c$ to avoid confusion between `s' and 
$s$ and $s'$.


		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:c-tab}{preliminaries/C-table}{0.3}
			{Table $C$ of number of occurrences in F of each symbol which
			sorts alphabetically before the displayed symbol.}

\clearpage			
		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:bws-1}{preliminaries/bwt-1}{0.5}
			{First stage of backwards search for `iss' on `mississippi'
			 string - before any rank queries have been made.}

\begin{enumerate}
	\item
		Starting from $s = 1$ and $e = 12$ as in Figure \ref{fig:bws-1},
		and $c = P[i] = $`s' where $i = 3$, we make our first two rank queries:
			$$s' = C[c] + rank(0, c) + 1 = 8 + 0 + 1 = 9$$
			$$e' = C[c] + rank(12, c) = 8 + 4 = 12$$
		
			%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
			\DefFig{fig:bws-2}{preliminaries/bwt-2}{0.5}
				{Second stage of backwards search for `iss' on `mississippi'
				string. All the occurrences of `s' lie in $SA[9..12]$.}
\clearpage				
	\item
		From $s = 9$ and $e = 11$ as in Figure \ref{fig:bws-2},
		and $c = P[i] = $`s' where $i = 2$, our next two rank queries are:
			$$s'' = C[c] + rank(8, c) + 1 = 8 + 2 + 1 = 11$$
			$$e'' = C[c] + rank(12, c) = 8 + 4 = 12$$
	
			
			%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
			\DefFig{fig:bws-3}{preliminaries/bwt-3}{0.5}
				{Third stage of backwards search for `iss' on `mississippi'
				string. All the occurrences of `ss' lie in $SA[11..12]$.}
	
	\item
		From $s = 11$ and $e = 12$ as in Figure \ref{fig:bws-3},
		and $c = P[i] = $`i' where $i = 1$, our final two rank queries are:
			$$s''' = C[c] + rank(10, c) + 1 = 1 + 2 + 1 = 4$$
			$$e''' = C[c] + rank(12, c) = 1 + 4 = 5$$
			
			
			%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
			\DefFig{fig:bws-4}{preliminaries/bwt-4}{0.5}
				{Fourth and final stage of backwards search for `iss' on
				`mississippi' string. All the occurrences of `iss' lie in
				$SA[4..5]$.}
				
\end{enumerate}

\clearpage
\subsection{Binary Wavelet Trees}
One of the most effective datas tructures for answering rank queries is the Wavelet Tree \cite{claude2008, FGM09, ferragina07, GGV03, MN07:selfindex}.

Binary Wavelet Trees encode the BWT as a perfect binary tree of bit vectors, to 
enable $O(\log \sigma)$ time rank queries, where $\sigma$ is the size of the alphabet. The tree is defined recursively as follows:

\begin{enumerate}
    \item
		Encoding half the alphabet as 0, and half as 1, for example:
    		$$\Sigma = \{ \$, i, m, p, s \}$$
			$$enc(\Sigma) = \{ 0, 0, 0, 1, 1 \}$$
    \item
		Group each 0-encoded symbol, $\{ \$, i, m \}$, as a sub-tree;
    \item
		Group each 1-encoded symbol, $\{ p, s \}$, as a sub-tree;
    \item
		Reapply to each sub-tree recursively until there is only one symbol
    	left.
\end{enumerate}

The encoded binary Wavelet Tree root node for the `mississippi` BWT is shown in Figure \ref{fig:wt-enc-bwt}. For a more detailed example see Figure \ref{fig:bin-wt-pp}.


		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:wt-enc-bwt}{preliminaries/encodebwt}{0.5}
			{Root node of Binary Wavelet Tree encoding for `mississippi' BWT.
			Each symbol in the string is assigned a bit (0 or 1) depending
			on which half of the alphabet it is from.}

After this, a rank query on a Wavelet Tree can be done with $\log \sigma$ binary 
rank queries on the bit vectors. For example, if we wanted to know $rank(6, e)$ 
in Figure \ref{fig:bin-wt-pp}, we use the following procedure which is 
illustrated in Figure \ref{fig:rank-bin-wt-pp}. We know that $enc(e) = 0$ at 
this level, so:

\begin{enumerate}
    \item
		At the root node, count the number of $0$s on $bitvector[1..6]$,
		which is given by $rank(6, 0) = 4$. This gives us the index to query in 
		our 0-child.
    \item
		Calculate $rank(4, 1) = 2$, as $e$ is now encoded as $1$. We traverse
    	the 1-branch this time, with the next index as $2$.
    \item
		$rank(2, 1) = 2$, which we use as the index in the child on the
    	1-branch, with our next index as $2$.
    \item
		$rank(2, 0) = 2$, as $e$ is encoded as $0$ here. Since our children at 
		this point are leaf nodes, we return $2$ as our result.
\end{enumerate}

Hence the result of $rank(6, e)$ is $2$. If we store these nodes in RRR, 
binary rank queries can be answered in $O(1)$ time.

		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:bin-wt-pp}{preliminaries/binwt}{1}
			{Binary Wavelet Tree for `Peter Piper...' where spaces are displayed
			as underscores.}
			
		\DefFig{fig:multi-wt-pp}{preliminaries/fourwt}{1}
			{4-ary Wavelet Tree for `Peter Piper...' where spaces are 
			displayed as underscores.}
\clearpage
		%%%%%%%%%%%%%%%%%%%% IMAGE %%%%%%%%%%%%%%%%%%%%
		\DefFig{fig:rank-bin-wt-pp}{preliminaries/binwt-query}{0.9}
			{Answering $rank(6, e)$ over the Binary Wavelet Tree for `Peter
			Piper...' where spaces are displayed as underscores.}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







\subsection{RRR}
RRR was first proposed by Raman et al. \cite{rrr2007}. The purpose of RRR is to
encode a bitsequence in such a way that supports $O(1)$ time binary rank 
queries. It also provides implicit zero-order empirical entropy compression, 
which is described in Section \ref{sec:entropy}.

To construct the RRR we divide the bit-vector into several so called 
\emph{superblocks}, we then divide these superblocks further, into 
\emph{blocks} of $b$ bits each, as in Figure \ref{fig:blocks}. We call the 
number of block in a superblock the \emph{superblock-factor}, $f$.

		\DefFig{fig:blocks}{preliminaries/blocks}{0.85}
			{Block division scheme for `Peter Piper...' Wavelet Tree's root
			node bit vector.}

For each of these blocks we store a class number $c$, which in the binary case 
is the number of  $1$s in the block. This is used as a lookup key in a table 
$G$, which is a table of tables, and will be explained shortly. We also store 
offset $o$, which is an index into the table at $G[c]$. Each offset value $o$ 
tells us precisely which of the possible blocks of class $c$ a block is. See 
Figure \ref{fig:rrr-seq}.

$G$ is a table having subtables $G[c]$ for each class $c$. For every possible 
permutation of $c$ 1-bits, $G[c]$ contains an array of cumulative sums for each 
position in the block of given offset and class - this is illustrated in Figure \ref{fig:bin-gtab}. It is important to note that 
the size of $o$ varies, since the number of possible permutations of $c$ bits, 
and hence entries in $G[c]$, is $b \choose c$, and can be encoded in $\log {b 
\choose c}$ bits.

The reason for grouping blocks into superblocks is to avoid iterating over each
block to answer a rank query; a query requires the sum of the ranks of previous
blocks as well, as depicted in See Figure \ref{fig:rrr-seq}. If we store the sum 
of all block ranks up to a superblock boundary, then a rank query $rank(i, c)$ 
can be answered like so:

\begin{enumerate}
	\item
		Calculate which block our index is in as $i_b = i / b$.
	\item
		Calculate which superblock our block resides in as $i_s = i_b / f$.
	\item
		Set \texttt{result} to the sum of previous ranks at $i_s$ boundary (which is 
		pre-calculated).
	\item
		Using each blocks class-offset pair $(c, o)$ after the boundary at 
		$i_s$, add the rank for that entire block to \texttt{result}.
	\item
		Repeat previous step until we reach $i_b$. We then add $rank_{i_b}(j, 
		c)$ to our result, where $j = i \mod b$, and is the position we are 
		querying local to $i_b$. Our final answer is \texttt{result}.
\end{enumerate}

Super blocks also provide an initial address for the variable-length offset 
values. After finding the first offset address in a superblock, we calculate the 
next offset address in bits according to the blocks class $c$ as $\lceil\log 
{b \choose c}\rceil$ bits, which we add to the current address. See Figure 
\ref{fig:rrr-seq}, which shows what is calculated for each 
superblock\footnote{We omit the first superblock, since the first offset address 
is easy to find, and the sum of ranks before the first superblock is always 
$0$.}.

		\DefFig{fig:bin-gtab}{preliminaries/binary-g-table}{0.7}
		{Binary RRR Count Table, with example lookup for class $c = 2$
		and offset $o = 3$ in a RRR sequence.}

		\DefFig{fig:rrr-seq}{preliminaries/superblocks}{0.9}
		{RRR Sequence divided into three superblocks. For each superblock
		boundary, a sum of previous ranks is stored, as well as the address
		of the first offset value. These allow us to reduce the amount of 
		iteration required to answer a rank query.}

It is possible to support Multiary Wavelet Trees using RRR with a more extensive 
class allocation, which we will discuss in Section \ref{sec:gen-rrr}.

\subsubsection{Zero-Order Entropy Compression}
\label{sec:entropy}
Zero-order empirical entropy is a lower bound for the average codeword size
when a symbol is mapped to the same code word irrespective or the context in
which they appear. It can be calculated as $H_0(S) = \sum_{i = 1}^{\sigma}
\frac{N^i}{N} \log \frac{N}{N^i}$, for an alphabet $\Sigma$ size of $\sigma$, 
and $N^i$ is the number of occurrences of the $i^{th}$ element of $\Sigma$ in 
our text $S[1..N]$. 
%The overall space requirement is $NH_0 + O(N \log \log N / \log N)$ bits \cite.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\subsection{Multiary Wavelet Trees}
Multiary Wavelet Trees are analogous to their binary counterparts, although now we encode each node recursively like so:

\begin{enumerate}
    \item Encoding one $A^{th}$ of the alphabet as $0$, the next $A^{th}$ as 
		$1$, the next $N^{th}$ as $2$ and so on until $A-1$. For example, with 
		the `Peter Piper...' string:
		$$\Sigma = \{ \$, \_, P, a, c, d, e, f, i, k, l, o, p, r, s, t \}$$
	   	$$enc(\Sigma) = \{  0,  0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3 \}$$
    \item Group each 0-encoded symbol as a sub-tree
    \item Group each 1-encoded symbol as a sub-tree
    \item Group each 2-encoded symbol as a sub-tree, and so on until $A-1$
    \item Reapply to each sub-tree recursively until the amount of symbols is
	less than or equal to $A - 1$.
\end{enumerate}

See Figure \ref{fig:multi-wt-pp} for a Multiary Wavelet Tree constructed over
the `Peter Piper...' string.

We can not use binary rank queries, and hence Binary RRR, the same way as we do 
with a Binary Wavelet Tree. We discuss three alternative approaches in the 
following sections.

\subsubsection{Multiary Wavelet Tree Variation 1 : Uncompressed}
		\DefFig{fig:bitmaps}{preliminaries/bitmaps}{0.4}
		{Concatenated bitmap binary encoding of multiary Wavelet Tree Node
		representing `eeecedecfcedee' from the `Peter Piper...' string.}
		
It is possible to represent each encoded symbol $c$, where $c$ is an element of
${ 0, 1,..., A - 1}$ and $A$ is the arity, using $A$ bitmaps. First we construct
the bitmaps for each symbol, as in Figure \ref{fig:bitmaps}, then we concatenate 
these bitmaps and store them as one 
bit-vector. A rank query then involves a ranged binary rank query on $N[c L, c L 
+ i]$ at each node $N$, where $L$ is the length of the node string before 
concatenation, and $i$ is the position.

We use $A$ bits per symbol, when they could be represented in $\log A$ bits, but
this allows us to utilise binary RRR.

\subsubsection{Multiary Wavelet Tree Variation 2 : Multi-Binary RRR}
Like the uncompressed version, bitmaps are created for each symbol and 
concatenated, but the bit-vector is stored in a binary RRR sequence. A query 
then becomes two binary rank queries\footnote{In our implementation we 
pre-calculate the first binary rank queries for each symbol and store it with 
the node.};

	\begin{align}
	rank(c * L - 1, 1) \\
	rank(c * L + i, 1)
	\end{align}

Where $c$ is the symbol we are querying at position $i$,
$c > 0$, and $L$ is 
the original length before concatenation. If $c = 0$ then we say the result of 
the first binary rank query is $0$. The final result of $rank(i, c)$ is 
calculated as the second binary rank query minus the first.

This variation means that we won't need to store a bigger $G$ table to 
accommodate the additional classes when increasing the arity, when compared with
a generalised RRR structure, but does not offer the same sequence compression as
the concatenated bitmaps take more bits than required.

Our third variation stores the symbols (without binary encoding) in a 
generalised RRR structure.

\subsection{Generalised RRR}
\label{sec:gen-rrr}

\DefFig{fig:gen-gtab}{preliminaries/multi-g-table}{1}
	{4-ary RRR Count Table, with example lookup for class $c = 2$, 
	which represents $(2, 2, 0, 1)$, and offset $o = 3$ in a RRR
	sequence.}
	
The purpose of the Generalised RRR structure is to provide $O(1)$ time rank
queries and compression of a sequence of small integers on the range 
$[0..A-1]$ for arity $A$. This requires these differences:

\begin{itemize}
	\item
		Rather than simply being the number of 1-bits, classes are now 
		considered to be a tuple of $(N^0, N^1, ..., N^{A-1})$ for a given 
		block, where $N^0$ is the number of $0$s, $N^1$ is the number of $1$s, 
		and so on. The RRR sequence still stores classes as a unique integer, 
		though.

	\item
		Rather than having $b \choose N^1$ permutations per class for blocksize 
		$b$, there are now ${b \choose N^0, N^1,...,N^{A-1}} = 
		\prod_{i = 1}^{A} {{b - \sum_{j = 1}^{i - 1} N^j} \choose N^i}
		$ different permutations\footnote{This grows rapidly as arity increases, 
		so our implementation only stored the classes and offsets that we 
		encountered in an attempt to make use of sparsity.}.
		Each offset value $o$ therefore requires $\lceil\log {b \choose N^0, 
		N^1,...,N^{A-1}}\rceil$ bits.

	\item
		The $G$ table must also store cumulative ranks for each symbol, per 
		permutation. See Figure \ref{fig:gen-gtab}.

	\item
		Each superblock now has $A$ rank sums of each previous block - a rank 
		sum for each symbol.
\end{itemize}
